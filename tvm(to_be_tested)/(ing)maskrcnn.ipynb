{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://discuss.tvm.apache.org/t/failures-using-many-of-onnx-model-zoo-models/10268\n",
    "supposed to use specific torch/torchvision version and transfer through pytorch script"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table of Contents\n",
    "1. [Summary](#su)\n",
    "2. [Dependency](#de)\n",
    "3. [Config](#cfg)\n",
    "4. [Exporting Model](#em)\n",
    "5. [Loading TVM Module & Compiling TVM](#tvm)\n",
    "6. [Inference](#in)\n",
    "7. [Auto Schedule](#as)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "1. The following packages' version should match: \n",
    "        pip install torch==1.7.0\n",
    "        pip install torchvision==0.8.1\n",
    "\n",
    "2. Transfer to tvm only successfully using torch.jit.trace. (ONNX files failed)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <a name=\"de\">Dependency"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !wget https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip\n",
    "# !unzip PennFudanPed.zip\n",
    "!pip uninstall -y torch torchvision\n",
    "!pip install torch==1.7.0\n",
    "!pip install torchvision==0.8.1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import onnx\n",
    "\n",
    "import tvm\n",
    "from tvm import relay, autotvm\n",
    "from tvm.relay import testing\n",
    "from tvm.runtime.vm import VirtualMachine\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "from tvm.autotvm.graph_tuner import DPTuner, PBQPTuner\n",
    "import tvm.contrib.graph_executor as runtime\n",
    "\n",
    "import cv2\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T04:54:02.362655Z",
     "start_time": "2021-08-01T04:54:02.356561Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <a name=\"cfg\">Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Define the neural network and compilation target.\n",
    "# If the target machine supports avx512 instructions, replace the\n",
    "# \"llvm -mcpu=core-avx2\" with \"llvm -mcpu=skylake-avx512\"\n",
    "class cfg:\n",
    "    model_name = \"mask_rcnn\"\n",
    "    model_path = f\"ONNX_MODELS/{model_name}.onnx\"\n",
    "    input_name = \"input0\"\n",
    "\n",
    "    use_sparse = False\n",
    "    batch_size = 1\n",
    "    input_shape = (3, 224, 224)\n",
    "    output_shape = (batch_size, 801)\n",
    "    dtype = \"float32\"\n",
    "    layout = \"NCHW\"    \n",
    "    opset_version = 11\n",
    "    target = \"llvm\"\n",
    "#     graph_opt_sch_file = \"...\"\n",
    "#     log_file = \"...\"\n",
    "    json_file = \"TVM_FILES/%s-%s-B%d-%s.json\" % (model_name, layout, batch_size, target.kind.name)\n",
    "#     Set number of threads used for tuning based on the number ofphysical CPU cores on your machine.\n",
    "    num_threads = 2\n",
    "    dev = tvm.device(str(target), 0)\n",
    "\n",
    "#     new\n",
    "    output_name = \"output\"\n",
    "    image_dir = '~/PennFudanPed/PNGImages'\n",
    "    image_paths = [os.path.join(root, file) for root, _, files in os.walk(image_dir) for file in files]\n",
    "    dynamic_model_path = f\"ONNX_MODELS/dynamic_{model_name}.onnx\"\n",
    "    score_threshold = 0.9\n",
    "    \n",
    "os.environ[\"TVM_NUM_THREADS\"] = str(cfg.num_threads)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T17:06:00.902753Z",
     "start_time": "2021-07-31T17:06:00.883274Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <a name=\"em\">Exporting model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def dict_to_tuple(out_dict):\n",
    "    if \"masks\" in out_dict.keys():\n",
    "        return out_dict[\"boxes\"], out_dict[\"scores\"], out_dict[\"labels\"], out_dict[\"masks\"]\n",
    "    return out_dict[\"boxes\"], out_dict[\"scores\"], out_dict[\"labels\"]\n",
    "\n",
    "\n",
    "class TraceWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, inp):\n",
    "        out = self.model(inp)\n",
    "        return dict_to_tuple(out[0])  \n",
    "    \n",
    "def do_trace(model, inp):\n",
    "    model_trace = torch.jit.trace(model, inp)\n",
    "    model_trace.eval()\n",
    "    return model_trace"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model\n",
    "model_func = torchvision.models.detection.maskrcnn_resnet50_fpn\n",
    "model = TraceWrapper(model_func(pretrained=True))\n",
    "model.eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## To Onnx Files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data_shape = (cfg.batch_size,) + cfg.input_shape\n",
    "input_data = torch.randn(data_shape)\n",
    "input_names = [cfg.input_name]\n",
    "output_names = [cfg.output_name]\n",
    "dynamic_axes = {cfg.input_name: {2:'width', 3:'height'}, cfg.output_name : {2:'width', 3:'height'}}\n",
    "\n",
    "# static model\n",
    "torch.onnx.export(model, input_data, cfg.model_path, input_names=input_names, verbose=True, opset_version=cfg.opset_version)\n",
    "check_onnx_model(cfg.model_path)\n",
    "\n",
    "# dynamic model\n",
    "torch.onnx.export(model, input_data, cfg.dynamic_model_path, input_names=input_names, output_names=output_names, dynamic_axes=dynamic_axes, opset_version=cfg.opset_version)\n",
    "check_onnx_model(cfg.dynamic_model_path)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T04:54:17.418549Z",
     "start_time": "2021-08-01T04:54:17.415650Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using torch.jit.trace"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_shape = (cfg.batch_size,) + cfg.input_shape\n",
    "shape_list = [(cfg.input_name, data_shape)]\n",
    "shape_dict = {input_name: data_shape}\n",
    "inp = torch.Tensor(np.random.uniform(0.0, 250.0, size=data_shape))\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(inp)\n",
    "    script_module = do_trace(model, inp)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <a name=\"tvm\">Loading TVM Module & Compiling TVM</a>\n",
    "* Loading module through onnx files failed.\n",
    "* Should use tvm virtual machine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pytorch\n",
    "mod, params = relay.frontend.from_pytorch(script_module, shape_list)\n",
    "    \n",
    "## onnx fails\n",
    "# onnx_model = onnx.load(cfg.model_path)\n",
    "# mod, params = relay.frontend.from_onnx(onnx_model, shape=shape_dict, dtype=cfg.dtype)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # onnx / keras\n",
    "with tvm.transform.PassContext(opt_level=3, disabled_pass=[\"FoldScaleAxis\"]):\n",
    "    intrp = relay.build_module.create_executor(\"vm\", mod, tvm.cpu(0), cfg.target)    \n",
    "\n",
    "tvm_output = intrp.evaluate()(tvm.nd.array(torch.randn(data_shape).astype(cfg.dtype)), **params).numpy()\n",
    "\n",
    "# # pytorch / tf / mxnet / tflite / coreml / darknet / caffe\n",
    "# with tvm.transform.PassContext(opt_level=3, disabled_pass=[\"FoldScaleAxis\"]):\n",
    "#     lib = relay.build(mod, target=target, params=params)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# vm\n",
    "# with tvm.transform.PassContext(opt_level=3, disabled_pass=[\"FoldScaleAxis\"]):\n",
    "#     vm_exec = relay.vm.compile(mod, target=target, params=params)\n",
    "    \n",
    "# vm = VirtualMachine(vm_exec, dezv)\n",
    "vm.set_input(\"main\", **{cfg.input_name: img})\n",
    "tvm_res = vm.run()\n",
    "\n",
    "boxes = tvm_res[0].numpy().tolist()\n",
    "valid_boxes = []\n",
    "for i, score in enumerate(tvm_res[1].numpy().tolist()):\n",
    "    if score > cfg.score_threshold:\n",
    "        valid_boxes.append(boxes[i])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"Get {} valid boxes\".format(len(valid_boxes)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Get 12 valid boxes\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T17:17:46.519861Z",
     "start_time": "2021-07-31T17:16:45.307864Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <a name=\"inf\">Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "img_url = (\n",
    "    \"https://raw.githubusercontent.com/dmlc/web-data/\" \"master/gluoncv/detection/street_small.jpg\"\n",
    ")\n",
    "from tvm.contrib.download import download_testdata\n",
    "img_path = download_testdata(img_url, \"test_street_small.jpg\", module=\"data\")\n",
    "\n",
    "img = cv2.imread(img_path).astype(cfg.dtype)\n",
    "img = cv2.resize(img, cfg.input_shape[1:])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = np.transpose(img / 255.0, [2, 0, 1])\n",
    "img = np.expand_dims(img, axis=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File /home/luhsuanwen/.tvm_test_data/data/test_street_small.jpg exists, skip.\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T17:14:24.478374Z",
     "start_time": "2021-07-31T17:14:24.463131Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with autotvm.apply_graph_best(cfg.graph_opt_sch_file):\n",
    "    print(\"Compile...\")\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        lib = relay.build_module.build(mod, target=cfg.target, params=params)\n",
    "\n",
    "        # upload parameters to device\n",
    "\n",
    "        module = runtime.GraphModule(lib[\"default\"](cfg.dev))\n",
    "\n",
    "def inference(img):\n",
    "    module.set_input(cfg.input_name, tvm.nd.array(img.astype(cfg.dtype)))\n",
    "    module.run()\n",
    "    tvm_output = m.get_output(0)\n",
    "    return tvm_output\n",
    "\n",
    "inference(img)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <a name=\"as\">Auto Schedule"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from tvm import relay, auto_scheduler\n",
    "from tvm.relay import data_dep_optimization as ddo\n",
    "import tvm.relay.testing\n",
    "from tvm.contrib import graph_executor"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T18:06:06.564756Z",
     "start_time": "2021-07-31T18:06:06.558777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def get_tvm_module_N_params(\n",
    "    model_path, \n",
    "    input_name=\"input.1\",\n",
    "    batch_size=1,\n",
    "    input_shape=(3, 224, 224),\n",
    "    layout=\"NHWC\", \n",
    "    dtype=\"float32\", \n",
    "    use_sparse=False\n",
    "):\n",
    "    \"\"\"Get the symbol definition and random weight of a network\"\"\"\n",
    "\n",
    "    data_shape = (batch_size,) + input_shape\n",
    "    # auto-scheduler prefers NHWC layout\n",
    "    assert layout == \"NCHW\"\n",
    "    mod, params = get_network_from_onnx(model_path, input_name, data_shape, dtype)\n",
    "    mod = convert_layout(mod)\n",
    "    net = mod[\"main\"]\n",
    "#     net = relay.Function(net.params, relay.nn.softmax(net.body), None, net.type_params, net.attrs)\n",
    "#     mod = tvm.IRModule.from_expr(net)\n",
    "\n",
    "    if use_sparse:\n",
    "        from tvm.topi.sparse.utils import convert_model_dense_to_sparse\n",
    "        mod, params = convert_model_dense_to_sparse(mod, params, bs_r=4, random_params=True)\n",
    "    return mod, params\n",
    "\n",
    "def run_tuning(tasks, task_weights, json_file, trials=1000, use_sparse=False):\n",
    "    print(\"Begin tuning...\")\n",
    "    tuner = auto_scheduler.TaskScheduler(tasks, task_weights)\n",
    "    tune_option = auto_scheduler.TuningOptions(\n",
    "        num_measure_trials=trials,  # change this to 20000 to achieve the best performance\n",
    "        runner=auto_scheduler.LocalRunner(repeat=10, enable_cpu_cache_flush=True),\n",
    "        measure_callbacks=[auto_scheduler.RecordToFile(json_file)],\n",
    "    )\n",
    "\n",
    "    if use_sparse:\n",
    "        from tvm.topi.sparse.utils import sparse_sketch_rules\n",
    "\n",
    "        search_policy = [\n",
    "            auto_scheduler.SketchPolicy(\n",
    "                task,\n",
    "                program_cost_model=auto_scheduler.XGBModel(),\n",
    "                init_search_callbacks=sparse_sketch_rules(),\n",
    "            )\n",
    "            for task in tasks\n",
    "        ]\n",
    "\n",
    "        tuner.tune(tune_option, search_policy=search_policy)\n",
    "    else:\n",
    "        tuner.tune(tune_option)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Extract tasks from the network\n",
    "print(\"Get module...\")\n",
    "mod, params = get_tvm_module_N_params(\n",
    "    cfg.model_path, \n",
    "    input_name=cfg.input_name,\n",
    "    batch_size=cfg.batch_size\n",
    "    input_shape=cfg.input_shape,\n",
    "    layout=cfg.layout,\n",
    "    dtype=cfg.dtype,\n",
    "    use_sparse=cfg.use_sparse,\n",
    ")\n",
    "print(\"Extract tasks...\")\n",
    "tasks, task_weights = auto_scheduler.extract_tasks(mod[\"main\"], params, cfg.target)\n",
    "\n",
    "for idx, task in enumerate(tasks):\n",
    "    print(\"========== Task %d  (workload key: %s) ==========\" % (idx, task.workload_key))\n",
    "    print(task.compute_dag)\n",
    "    \n",
    "\n",
    "run_tuning(tasks, task_weights, cfg.json_file)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Get errors with GraphExecutorCodegen for task extraction. Fallback to VMCompiler.\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-31T18:06:21.981Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}