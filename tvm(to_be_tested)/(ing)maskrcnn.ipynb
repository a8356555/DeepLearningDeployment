{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5323fe35",
   "metadata": {},
   "source": [
    "https://discuss.tvm.apache.org/t/failures-using-many-of-onnx-model-zoo-models/10268",
    "supposed to use specific torch/torchvision version and transfer through pytorch script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ffdde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip\n",
    "# !unzip PennFudanPed.zip\n",
    "!pip uninstall -y torch torchvision\n",
    "!pip install torch==1.7.0\n",
    "!pip install torchvision==0.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55623750",
   "metadata": {},
   "source": [
    "# Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca0f7729",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T04:54:02.362655Z",
     "start_time": "2021-08-01T04:54:02.356561Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import onnx\n",
    "\n",
    "import tvm\n",
    "from tvm import relay, autotvm\n",
    "from tvm.relay import testing\n",
    "from tvm.runtime.vm import VirtualMachine\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "from tvm.autotvm.graph_tuner import DPTuner, PBQPTuner\n",
    "import tvm.contrib.graph_executor as runtime\n",
    "\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07408b1",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df534d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T17:06:00.902753Z",
     "start_time": "2021-07-31T17:06:00.883274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the neural network and compilation target.\n",
    "# If the target machine supports avx512 instructions, replace the\n",
    "# \"llvm -mcpu=core-avx2\" with \"llvm -mcpu=skylake-avx512\"\n",
    "class cfg:\n",
    "    model_name = \"mask_rcnn\"\n",
    "    model_path = f\"ONNX_MODELS/{model_name}.onnx\"\n",
    "    input_name = \"input0\"\n",
    "\n",
    "    use_sparse = False\n",
    "    batch_size = 1\n",
    "    input_shape = (3, 224, 224)\n",
    "    output_shape = (batch_size, 801)\n",
    "    dtype = \"float32\"\n",
    "    layout = \"NCHW\"    \n",
    "    opset_version = 11\n",
    "    target = \"llvm\"\n",
    "#     graph_opt_sch_file = \"...\"\n",
    "#     log_file = \"...\"\n",
    "    json_file = \"TVM_FILES/%s-%s-B%d-%s.json\" % (model_name, layout, batch_size, target.kind.name)\n",
    "#     Set number of threads used for tuning based on the number ofphysical CPU cores on your machine.\n",
    "    num_threads = 2\n",
    "    dev = tvm.device(str(target), 0)\n",
    "\n",
    "#     new\n",
    "    output_name = \"output\"\n",
    "    image_dir = '~/PennFudanPed/PNGImages'\n",
    "    image_paths = [os.path.join(root, file) for root, _, files in os.walk(image_dir) for file in files]\n",
    "    dynamic_model_path = f\"ONNX_MODELS/dynamic_{model_name}.onnx\"\n",
    "    score_threshold = 0.9\n",
    "    \n",
    "os.environ[\"TVM_NUM_THREADS\"] = str(cfg.num_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa75eaf",
   "metadata": {},
   "source": [
    "# export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_tuple(out_dict):\n",
    "    if \"masks\" in out_dict.keys():\n",
    "        return out_dict[\"boxes\"], out_dict[\"scores\"], out_dict[\"labels\"], out_dict[\"masks\"]\n",
    "    return out_dict[\"boxes\"], out_dict[\"scores\"], out_dict[\"labels\"]\n",
    "\n",
    "\n",
    "class TraceWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, inp):\n",
    "        out = self.model(inp)\n",
    "        return dict_to_tuple(out[0])  \n",
    "    \n",
    "def do_trace(model, inp):\n",
    "    model_trace = torch.jit.trace(model, inp)\n",
    "    model_trace.eval()\n",
    "    return model_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model_func = torchvision.models.detection.maskrcnn_resnet50_fpn\n",
    "model = TraceWrapper(model_func(pretrained=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454dc047",
   "metadata": {},
   "source": [
    "## onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1decb797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T04:54:17.418549Z",
     "start_time": "2021-08-01T04:54:17.415650Z"
    }
   },
   "outputs": [],
   "source": [
    "data_shape = (cfg.batch_size,) + cfg.input_shape\n",
    "input_data = torch.randn(data_shape)\n",
    "input_names = [cfg.input_name]\n",
    "output_names = [cfg.output_name]\n",
    "dynamic_axes = {cfg.input_name: {2:'width', 3:'height'}, cfg.output_name : {2:'width', 3:'height'}}\n",
    "\n",
    "# static model\n",
    "torch.onnx.export(model, input_data, cfg.model_path, input_names=input_names, verbose=True, opset_version=cfg.opset_version)\n",
    "check_onnx_model(cfg.model_path)\n",
    "\n",
    "# dynamic model\n",
    "torch.onnx.export(model, input_data, cfg.dynamic_model_path, input_names=input_names, output_names=output_names, dynamic_axes=dynamic_axes, opset_version=cfg.opset_version)\n",
    "check_onnx_model(cfg.dynamic_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c820d92",
   "metadata": {},
   "source": [
    "# Loading tvm module from pytorch script model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f91c43a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T04:54:28.861334Z",
     "start_time": "2021-08-01T04:54:28.858292Z"
    }
   },
   "outputs": [],
   "source": [
    "data_shape = (cfg.batch_size,) + cfg.input_shape\n",
    "shape_list = [(cfg.input_name, data_shape)]\n",
    "shape_dict = {input_name: data_shape}\n",
    "inp = torch.Tensor(np.random.uniform(0.0, 250.0, size=data_shape))\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(inp)\n",
    "    script_module = do_trace(model, inp)\n",
    "\n",
    "# pytorch\n",
    "mod, params = relay.frontend.from_pytorch(script_module, shape_list)\n",
    "    \n",
    "## onnx fails\n",
    "# onnx_model = onnx.load(cfg.model_path)\n",
    "# mod, params = relay.frontend.from_onnx(onnx_model, shape=shape_dict, dtype=cfg.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56a8d0",
   "metadata": {},
   "source": [
    "# Compiling TVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # onnx / keras\n",
    "with tvm.transform.PassContext(opt_level=3, disabled_pass=[\"FoldScaleAxis\"]):\n",
    "    intrp = relay.build_module.create_executor(\"vm\", mod, tvm.cpu(0), cfg.target)    \n",
    "\n",
    "tvm_output = intrp.evaluate()(tvm.nd.array(torch.randn(data_shape).astype(cfg.dtype)), **params).numpy()\n",
    "\n",
    "# # pytorch / tf / mxnet / tflite / coreml / darknet / caffe\n",
    "# with tvm.transform.PassContext(opt_level=3, disabled_pass=[\"FoldScaleAxis\"]):\n",
    "#     lib = relay.build(mod, target=target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97fef329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T17:59:03.847559Z",
     "start_time": "2021-07-31T17:59:03.840423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(VMExecutable, 35c55608)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm_exec.primitive_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3641c2a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T17:17:46.519861Z",
     "start_time": "2021-07-31T17:16:45.307864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get 12 valid boxes\n"
     ]
    }
   ],
   "source": [
    "# vm\n",
    "# with tvm.transform.PassContext(opt_level=3, disabled_pass=[\"FoldScaleAxis\"]):\n",
    "#     vm_exec = relay.vm.compile(mod, target=target, params=params)\n",
    "    \n",
    "# vm = VirtualMachine(vm_exec, dezv)\n",
    "vm.set_input(\"main\", **{cfg.input_name: img})\n",
    "tvm_res = vm.run()\n",
    "\n",
    "boxes = tvm_res[0].numpy().tolist()\n",
    "valid_boxes = []\n",
    "for i, score in enumerate(tvm_res[1].numpy().tolist()):\n",
    "    if score > cfg.score_threshold:\n",
    "        valid_boxes.append(boxes[i])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"Get {} valid boxes\".format(len(valid_boxes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa9be8",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f254b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T17:14:24.478374Z",
     "start_time": "2021-07-31T17:14:24.463131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/luhsuanwen/.tvm_test_data/data/test_street_small.jpg exists, skip.\n"
     ]
    }
   ],
   "source": [
    "img_url = (\n",
    "    \"https://raw.githubusercontent.com/dmlc/web-data/\" \"master/gluoncv/detection/street_small.jpg\"\n",
    ")\n",
    "from tvm.contrib.download import download_testdata\n",
    "img_path = download_testdata(img_url, \"test_street_small.jpg\", module=\"data\")\n",
    "\n",
    "img = cv2.imread(img_path).astype(cfg.dtype)\n",
    "img = cv2.resize(img, cfg.input_shape[1:])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = np.transpose(img / 255.0, [2, 0, 1])\n",
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38feac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with autotvm.apply_graph_best(cfg.graph_opt_sch_file):\n",
    "    print(\"Compile...\")\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        lib = relay.build_module.build(mod, target=cfg.target, params=params)\n",
    "\n",
    "        # upload parameters to device\n",
    "\n",
    "        module = runtime.GraphModule(lib[\"default\"](cfg.dev))\n",
    "\n",
    "def inference(img):\n",
    "    module.set_input(cfg.input_name, tvm.nd.array(img.astype(cfg.dtype)))\n",
    "    module.run()\n",
    "    tvm_output = m.get_output(0)\n",
    "    return tvm_output\n",
    "\n",
    "inference(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724f152",
   "metadata": {},
   "source": [
    "# Auto Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daf29082",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T18:06:06.564756Z",
     "start_time": "2021-07-31T18:06:06.558777Z"
    }
   },
   "outputs": [],
   "source": [
    "from tvm import relay, auto_scheduler\n",
    "from tvm.relay import data_dep_optimization as ddo\n",
    "import tvm.relay.testing\n",
    "from tvm.contrib import graph_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96611aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tvm_module_N_params(\n",
    "    model_path, \n",
    "    input_name=\"input.1\",\n",
    "    batch_size=1,\n",
    "    input_shape=(3, 224, 224),\n",
    "    layout=\"NHWC\", \n",
    "    dtype=\"float32\", \n",
    "    use_sparse=False\n",
    "):\n",
    "    \"\"\"Get the symbol definition and random weight of a network\"\"\"\n",
    "\n",
    "    data_shape = (batch_size,) + input_shape\n",
    "    # auto-scheduler prefers NHWC layout\n",
    "    assert layout == \"NCHW\"\n",
    "    mod, params = get_network_from_onnx(model_path, input_name, data_shape, dtype)\n",
    "    mod = convert_layout(mod)\n",
    "    net = mod[\"main\"]\n",
    "#     net = relay.Function(net.params, relay.nn.softmax(net.body), None, net.type_params, net.attrs)\n",
    "#     mod = tvm.IRModule.from_expr(net)\n",
    "\n",
    "    if use_sparse:\n",
    "        from tvm.topi.sparse.utils import convert_model_dense_to_sparse\n",
    "        mod, params = convert_model_dense_to_sparse(mod, params, bs_r=4, random_params=True)\n",
    "    return mod, params\n",
    "\n",
    "def run_tuning(tasks, task_weights, json_file, trials=1000, use_sparse=False):\n",
    "    print(\"Begin tuning...\")\n",
    "    tuner = auto_scheduler.TaskScheduler(tasks, task_weights)\n",
    "    tune_option = auto_scheduler.TuningOptions(\n",
    "        num_measure_trials=trials,  # change this to 20000 to achieve the best performance\n",
    "        runner=auto_scheduler.LocalRunner(repeat=10, enable_cpu_cache_flush=True),\n",
    "        measure_callbacks=[auto_scheduler.RecordToFile(json_file)],\n",
    "    )\n",
    "\n",
    "    if use_sparse:\n",
    "        from tvm.topi.sparse.utils import sparse_sketch_rules\n",
    "\n",
    "        search_policy = [\n",
    "            auto_scheduler.SketchPolicy(\n",
    "                task,\n",
    "                program_cost_model=auto_scheduler.XGBModel(),\n",
    "                init_search_callbacks=sparse_sketch_rules(),\n",
    "            )\n",
    "            for task in tasks\n",
    "        ]\n",
    "\n",
    "        tuner.tune(tune_option, search_policy=search_policy)\n",
    "    else:\n",
    "        tuner.tune(tune_option)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1f7db",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-31T18:06:21.981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get errors with GraphExecutorCodegen for task extraction. Fallback to VMCompiler.\n"
     ]
    }
   ],
   "source": [
    "# Extract tasks from the network\n",
    "print(\"Get module...\")\n",
    "mod, params = get_tvm_module_N_params(\n",
    "    cfg.model_path, \n",
    "    input_name=cfg.input_name,\n",
    "    batch_size=cfg.batch_size\n",
    "    input_shape=cfg.input_shape,\n",
    "    layout=cfg.layout,\n",
    "    dtype=cfg.dtype,\n",
    "    use_sparse=cfg.use_sparse,\n",
    ")\n",
    "print(\"Extract tasks...\")\n",
    "tasks, task_weights = auto_scheduler.extract_tasks(mod[\"main\"], params, cfg.target)\n",
    "\n",
    "for idx, task in enumerate(tasks):\n",
    "    print(\"========== Task %d  (workload key: %s) ==========\" % (idx, task.workload_key))\n",
    "    print(task.compute_dag)\n",
    "    \n",
    "\n",
    "run_tuning(tasks, task_weights, cfg.json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
