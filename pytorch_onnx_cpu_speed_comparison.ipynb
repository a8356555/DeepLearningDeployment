{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Result of speed comparison\n",
    "jump to\n",
    "1. [raw pytorch + cpu](#rcpu)\n",
    "2. [onnx + static + cpu](#onnxs)\n",
    "3. [onnx + dynamic + cpu](#onnxd)\n",
    "4. [outputs comparison](#out)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# install onnx / onnxruntim / efficientnet first\n",
    "import onnxruntime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from efficientnet_pytorch import EfficientNet"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T12:39:29.798450Z",
     "start_time": "2021-08-29T12:39:29.791484Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def pytorch_to_onnx(model, model_path, input_shape=(1, 3, 224, 224), opset_version=11):        \n",
    "    input_data = torch.randn(input_shape)\n",
    "    torch.onnx.export(model.eval(), input_data, model_path, opset_version=opset_version)\n",
    "    print('Export Finished, now Checking ONNX Model')    \n",
    "    get_and_check_onnx_model(model_path)\n",
    "\n",
    "\n",
    "def pytorch_to_onnx_dynamic(model, model_path, input_shape=(1, 3, 224, 224), opset_version=11):        \n",
    "    input_data = torch.randn(input_shape)\n",
    "    input_name = \"input.1\"\n",
    "    output_name = \"output\"\n",
    "    input_names = [input_name]\n",
    "    output_names = [output_name]\n",
    "    dynamic_axes = {input_name: {2:'width', 3:'height'}, output_name : {1:'classes'}}\n",
    "    torch.onnx.export(model, input_data, model_path, input_names=input_names, output_names=output_names, dynamic_axes=dynamic_axes, opset_version=opset_version)\n",
    "    print('Export Finished, now Checking ONNX Model')    \n",
    "    get_and_check_onnx_model(model_path)\n",
    "\n",
    "\n",
    "\n",
    "def time_calculator(func):\n",
    "    def wrap(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        time_spend = end - start\n",
    "        print('time_spend: ', time_spend)\n",
    "        return time_spend\n",
    "    return wrap\n",
    "    \n",
    "def get_and_check_onnx_model(model_path):\n",
    "    import onnx\n",
    "    onnx_model = onnx.load(model_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    print('if nothing showed, then the model is fine.')\n",
    "    return onnx_model\n",
    "\n",
    "def set_efficient_model_ready(model):\n",
    "    model.set_swish(memory_efficient=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "def _calculate_dhdw_half(h, w):\n",
    "    \"\"\"Calculate difference of h or w in order to get a square \"\"\"\n",
    "    if h > w:\n",
    "        dh_half = int(0.1*h/2)\n",
    "        dw_half = int((h+2*dh_half-w)/2)\n",
    "    else:\n",
    "        dw_half = int(0.1*w/2)\n",
    "        dh_half = int((w+2*dw_half-h)/2)\n",
    "    return dh_half, dw_half\n",
    "    \n",
    "def preprocess_onnx(image):\n",
    "    # 加邊框\n",
    "    h, w, c = image.shape\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    dh_half, dw_half = _calculate_dhdw_half(h, w)\n",
    "    image = cv2.copyMakeBorder(image, dh_half, dh_half, dw_half, dw_half, cv2.BORDER_REPLICATE)\n",
    "    image = cv2.resize(image, (248, 248))[12:236, 12:236]/255.0\n",
    "    image = image.transpose(2, 0, 1).astype(np.float32)[np.newaxis,:]\n",
    "    return image\n",
    "\n",
    "def preprocess_pt(image):\n",
    "    # 加邊框\n",
    "    h, w, c = image.shape\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    dh_half, dw_half = _calculate_dhdw_half(h, w)\n",
    "    image = cv2.copyMakeBorder(image, dh_half, dh_half, dw_half, dw_half, cv2.BORDER_REPLICATE)\n",
    "    image = cv2.resize(image, (248, 248))[12:236, 12:236]\n",
    "    tensor = torch.tensor(image, dtype=torch.float)    \n",
    "    return tensor.permute(2, 0, 1).div(255.0).unsqueeze(0)\n",
    "\n",
    "def show_onnx_session_io_name(session):\n",
    "    session.get_modelmeta()\n",
    "    first_input_name = session.get_inputs()[0].name\n",
    "    first_output_name = session.get_outputs()[0].name\n",
    "    print(path, first_input_name, first_output_name)\n",
    "    \n",
    "def onnxruntime_inference(image, ort_session):\n",
    "    image = preprocess_onnx(image)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: image}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    return ort_outs"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T12:43:35.461161Z",
     "start_time": "2021-08-29T12:43:35.438333Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "!pip install efficientnet_pytorch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def set_efficient_model_ready(model):\n",
    "    model.set_swish(memory_efficient=False)\n",
    "    return model\n",
    "\n",
    "model_name_list = [\"resnet50\", \"resnet101\", \"efficientnet-b4\", \"efficientnet-b5\", \"efficientnet-b6\", \"efficientnet-b7\"]\n",
    "model_path_list = []\n",
    "dynamic_model_path_list = []\n",
    "model_list = []\n",
    "class_num = 801\n",
    "for name in model_name_list:\n",
    "    if name.startswith(\"res\"):\n",
    "        model = getattr(models, name)(pretrained=True)\n",
    "        num_input_fts = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_input_fts, class_num)\n",
    "        torch.manual_seed(0)\n",
    "        w = torch.randn(class_num, num_input_fts)\n",
    "        b = torch.randn(class_num)\n",
    "        model.fc.bias.data = b\n",
    "        model.fc.weight.data = w\n",
    "    else:\n",
    "        model = EfficientNet.from_pretrained(name)\n",
    "        model = set_efficient_model_ready(model)\n",
    "        num_input_fts = model._fc.in_features\n",
    "        model._fc = nn.Linear(num_input_fts, class_num)\n",
    "        torch.manual_seed(0)        \n",
    "        w = torch.randn(class_num, num_input_fts)\n",
    "        b = torch.randn(class_num)\n",
    "        model._fc.bias.data = b\n",
    "        model._fc.weight.data = w\n",
    "    print(name)\n",
    "    print(w[0][:5])\n",
    "    model_path = f\"ONNX_MODELS/{name}.onnx\"\n",
    "    dynamic_model_path = f\"ONNX_MODELS/{name}_dynamic.onnx\"\n",
    "    model_path_list.append(model_path)\n",
    "    dynamic_model_path_list.append(dynamic_model_path)\n",
    "    model_list.append(model)\n",
    "    if os.path.exists(model_path):\n",
    "        continue\n",
    "    pytorch_to_onnx(model.eval(), model_path, opset_version=10)\n",
    "    pytorch_to_onnx_dynamic(model.eval(), dynamic_model_path, opset_version=10)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "resnet50\n",
      "tensor([-1.1258, -1.1524, -0.2506, -0.4339,  0.8487])\n",
      "resnet101\n",
      "tensor([-1.1258, -1.1524, -0.2506, -0.4339,  0.8487])\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "efficientnet-b4\n",
      "tensor([-1.1258, -1.1524, -0.2506, -0.4339,  0.8487])\n",
      "Loaded pretrained weights for efficientnet-b5\n",
      "efficientnet-b5\n",
      "tensor([-1.1258, -1.1524, -0.2506, -0.4339,  0.8487])\n",
      "Loaded pretrained weights for efficientnet-b6\n",
      "efficientnet-b6\n",
      "tensor([-1.1258, -1.1524, -0.2506, -0.4339,  0.8487])\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "efficientnet-b7\n",
      "tensor([-1.1258, -1.1524, -0.2506, -0.4339,  0.8487])\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T12:41:31.155797Z",
     "start_time": "2021-08-29T12:41:26.118703Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Raw Pytorch Speed\n",
    "<a href=\"#rcpu\"></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "n = 10\n",
    "raw_outputs = []\n",
    "for name, model in zip(model_name_list, model_list):\n",
    "    model.cpu()\n",
    "    model.eval() \n",
    "    start = time.time()\n",
    "    for _ in range(n):\n",
    "        test_image = cv2.imread(\"sample.jpg\")\n",
    "        tensor = preprocess_pt(test_image)\n",
    "        output = model(tensor.cpu())        \n",
    "        score, pred = torch.max(output, dim=1)\n",
    "    end = time.time()\n",
    "    raw_outputs.append(output)\n",
    "    print(name, (end-start)/n)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "resnet50 0.19793853759765626\n",
      "resnet101 0.3345116853713989\n",
      "efficientnet-b4 0.17874245643615722\n",
      "efficientnet-b5 0.2523103952407837\n",
      "efficientnet-b6 0.3270812273025513\n",
      "efficientnet-b7 0.4499534606933594\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T12:41:49.528010Z",
     "start_time": "2021-08-29T12:41:32.043312Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Onnx Static Speed\n",
    "<a href=\"#onnxs\"></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "onnx_outputs = []\n",
    "n = 10\n",
    "for name, model_path in zip(model_name_list, model_path_list):\n",
    "    \n",
    "    session = onnxruntime.InferenceSession(model_path)\n",
    "#     show_onnx_session_io_name(session)\n",
    "    start = time.time()\n",
    "    for _ in range(n):\n",
    "        test_image = cv2.imread(\"sample.jpg\")\n",
    "        outputs = onnxruntime_inference(test_image, session)\n",
    "    end = time.time()\n",
    "    onnx_outputs.append(outputs)\n",
    "    print(name, model_path, (end-start)/n)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "resnet50 ONNX_MODELS/resnet50.onnx 0.11168470382690429\n",
      "resnet101 ONNX_MODELS/resnet101.onnx 0.20166232585906982\n",
      "efficientnet-b4 ONNX_MODELS/efficientnet-b4.onnx 0.10989341735839844\n",
      "efficientnet-b5 ONNX_MODELS/efficientnet-b5.onnx 0.1590277910232544\n",
      "efficientnet-b6 ONNX_MODELS/efficientnet-b6.onnx 0.21927280426025392\n",
      "efficientnet-b7 ONNX_MODELS/efficientnet-b7.onnx 0.3087084531784058\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T12:14:12.704747Z",
     "start_time": "2021-08-29T12:13:57.861414Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Onnx Dynamic Speed\n",
    "<a href=\"#onnxd\"></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "onnx_dynamic_outputs = []\n",
    "n = 10\n",
    "for name, model_path in zip(model_name_list, dynamic_model_path_list):    \n",
    "    session = onnxruntime.InferenceSession(model_path)\n",
    "#     show_onnx_session_io_name(session)\n",
    "    start = time.time()\n",
    "    for _ in range(n):\n",
    "        test_image = cv2.imread(\"sample.jpg\")\n",
    "        outputs = onnxruntime_inference(test_image, session)\n",
    "    end = time.time()\n",
    "    onnx_dynamic_outputs.append(outputs)\n",
    "    print(name, model_path, (end-start)/n)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "resnet50 ONNX_MODELS/resnet50_dynamic.onnx 0.11474838256835937\n",
      "resnet101 ONNX_MODELS/resnet101_dynamic.onnx 0.20631396770477295\n",
      "efficientnet-b4 ONNX_MODELS/efficientnet-b4_dynamic.onnx 0.11047964096069336\n",
      "efficientnet-b5 ONNX_MODELS/efficientnet-b5_dynamic.onnx 0.15632407665252684\n",
      "efficientnet-b6 ONNX_MODELS/efficientnet-b6_dynamic.onnx 0.21250839233398439\n",
      "efficientnet-b7 ONNX_MODELS/efficientnet-b7_dynamic.onnx 0.30537655353546145\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T12:13:19.690291Z",
     "start_time": "2021-08-29T12:13:05.031924Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Output comparison\n",
    "<a href=\"#out\"></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def postprocess_onnx(onnx_outputs):\n",
    "    return onnx_outputs[0][0]\n",
    "\n",
    "def postprocess_pt_cpu(pt_outputs):\n",
    "    return pt_outputs.detach().numpy()[0]"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T12:17:42.966598Z",
     "start_time": "2021-08-29T12:17:42.960874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "for name, raw, onnx_, onnx_d in zip(model_name_list, raw_outputs, onnx_outputs, onnx_dynamic_outputs):\n",
    "    raw = postprocess_pt_cpu(raw)\n",
    "    onnx_ = postprocess_onnx(onnx_)\n",
    "    onnx_d = postprocess_onnx(onnx_d)\n",
    "    mse = np.mean((raw - onnx_)**2)\n",
    "    print(name, \", error: \", mse)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "resnet50 , error:  7.369016e-10\n",
      "resnet101 , error:  3.8520462e-10\n",
      "efficientnet-b4 , error:  3.3588207e-10\n",
      "efficientnet-b5 , error:  4.901697e-10\n",
      "efficientnet-b6 , error:  3.3645428e-10\n",
      "efficientnet-b7 , error:  9.3104985e-10\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T12:18:49.119986Z",
     "start_time": "2021-08-29T12:18:49.109196Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}